# KokoroTTS API - Docker Compose Configuration
# Supports CPU and GPU deployments with optional services
version: '3.8'

x-common-variables: &common-env
  # Application settings
  ENVIRONMENT: production
  HOST: 0.0.0.0
  PORT: 8000
  LOG_LEVEL: info
  DEBUG: false
  RELOAD: false
  
  # API configuration
  API_TITLE: "Kokoro TTS API"
  API_VERSION: "1.0.0"
  API_DESCRIPTION: "OpenAI-compatible TTS API using Kokoro model with voice blending support"
  API_DOCS_URL: "/docs"
  API_REDOC_URL: "/redoc"
  API_STATIC_DIRECTORY: "static"
  API_SUPPORTED_FORMATS: "wav,mp3,flac,ogg,opus"
  API_MIN_SPEED: 0.25
  API_MAX_SPEED: 4.0
  API_DEFAULT_LANGUAGE: "a"
  API_DEFAULT_VOICE: "af_heart"
  API_DEFAULT_FORMAT: "mp3"
  API_VOICE_CACHE_DURATION: 3600
  API_CORS_ORIGINS: "*"
  API_CORS_METHODS: "*"
  API_CORS_HEADERS: "*"
  API_ALLOW_CREDENTIALS: true
  
  # TTS Engine configuration
  KOKORO_DEVICE: auto
  KOKORO_SAMPLE_RATE: 24000
  KOKORO_DEFAULT_CHUNK_SIZE: 800
  KOKORO_MAX_CHUNK_SIZE: 1000
  KOKORO_STREAMING_CHUNK_SIZE: 800
  KOKORO_MP3_BITRATE: "192k"
  KOKORO_OPUS_CODEC: "libopus"
  KOKORO_MEMORY_LIMIT_MB: 1024
  KOKORO_BATCH_SIZE: 5
  KOKORO_CACHE_DIR: /app/cache
  KOKORO_MODEL_DIR: /app/models
  KOKORO_REPO_ID: "hexgrad/Kokoro-82M"
  
  # Security configuration
  SECURITY_API_KEY_ENABLED: false
  SECURITY_RATE_LIMIT_ENABLED: false
  SECURITY_RATE_LIMIT_PER_MINUTE: 60
  SECURITY_RATE_LIMIT_BURST: 10
  
  # Monitoring configuration
  MONITORING_HEALTH_CHECK_ENABLED: true
  MONITORING_HEALTH_CHECK_PATH: "/health"
  MONITORING_METRICS_ENABLED: true
  MONITORING_METRICS_PATH: "/metrics"
  MONITORING_LOG_FORMAT: "json"
  MONITORING_SENTRY_ENVIRONMENT: "production"
  
  # System paths and cache
  HOME: /home/kokorotts
  HF_HOME: /app/cache/huggingface
  TRANSFORMERS_CACHE: /app/cache/transformers

services:
  # Main KokoroTTS API service (CPU version)
  kokorotts-api:
    build:
      context: ..
      dockerfile: docker/Dockerfile.cpu
      args:
        BUILD_ENV: production
    container_name: kokorotts-api
    ports:
      - "8000:8000"
    environment:
      <<: *common-env
      WORKERS: 2
      KOKORO_DEVICE: cpu
      # CPU-specific optimizations
      KOKORO_DEFAULT_CHUNK_SIZE: 600
      KOKORO_MAX_CHUNK_SIZE: 800
      KOKORO_STREAMING_CHUNK_SIZE: 600
      KOKORO_MEMORY_LIMIT_MB: 768
      KOKORO_BATCH_SIZE: 3
      KOKORO_MP3_BITRATE: "128k"
      OMP_NUM_THREADS: 2
      MKL_NUM_THREADS: 2
      TORCH_NUM_THREADS: 2
      PYTHONMALLOC: malloc
      MALLOC_ARENA_MAX: 2
    volumes:
      # Model cache for persistence
      - kokorotts-models:/app/models
      - kokorotts-cache:/app/cache
      # Logs for debugging
      - kokorotts-logs:/app/logs
      # Optional: Mount static files for development
      # - ./static:/app/static:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "docker/healthcheck.py"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - kokorotts-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  # GPU version (uncomment to use instead of CPU version)
  # kokorotts-api-gpu:
  #   build:
  #     context: ..
  #     dockerfile: docker/Dockerfile.gpu
  #     args:
  #       BUILD_ENV: production
  #   container_name: kokorotts-api-gpu
  #   ports:
  #     - "8000:8000"
  #   environment:
  #     <<: *common-env
  #     WORKERS: 1
  #     KOKORO_DEVICE: cuda
  #     # GPU-specific optimizations
  #     KOKORO_DEFAULT_CHUNK_SIZE: 1200
  #     KOKORO_MAX_CHUNK_SIZE: 1500
  #     KOKORO_STREAMING_CHUNK_SIZE: 1000
  #     KOKORO_MEMORY_LIMIT_MB: 2048
  #     KOKORO_BATCH_SIZE: 8
  #     SECURITY_RATE_LIMIT_PER_MINUTE: 120
  #     SECURITY_RATE_LIMIT_BURST: 20
  #     # CUDA settings
  #     CUDA_VISIBLE_DEVICES: 0
  #     NVIDIA_VISIBLE_DEVICES: all
  #     NVIDIA_DRIVER_CAPABILITIES: compute,utility
  #     TORCH_CUDA_ARCH_LIST: "6.0;6.1;7.0;7.5;8.0;8.6"
  #   volumes:
  #     - kokorotts-models:/app/models
  #     - kokorotts-cache:/app/cache
  #     - kokorotts-logs:/app/logs
  #   restart: unless-stopped
  #   runtime: nvidia
  #   healthcheck:
  #     test: ["CMD", "python", "docker/healthcheck.py"]
  #     interval: 30s
  #     timeout: 15s
  #     retries: 3
  #     start_period: 90s
  #   networks:
  #     - kokorotts-network
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]

  # Nginx reverse proxy (optional for production)
  nginx:
    image: nginx:alpine
    container_name: kokorotts-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      kokorotts-api:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - kokorotts-network
    profiles:
      - production
      - nginx

  # Prometheus monitoring (optional)
  prometheus:
    image: prom/prometheus:latest
    container_name: kokorotts-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - kokorotts-network
    profiles:
      - monitoring

  # Grafana dashboard (optional)
  grafana:
    image: grafana/grafana:latest
    container_name: kokorotts-grafana
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_USERS_ALLOW_SIGN_UP: false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    networks:
      - kokorotts-network
    profiles:
      - monitoring

  # Redis cache (optional for enhanced performance)
  redis:
    image: redis:7-alpine
    container_name: kokorotts-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped
    networks:
      - kokorotts-network
    profiles:
      - cache
      - production

volumes:
  # Persistent volumes for application data
  kokorotts-models:
    driver: local
  kokorotts-cache:
    driver: local
  kokorotts-logs:
    driver: local
  
  # Monitoring volumes
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  
  # Cache volume
  redis-data:
    driver: local

networks:
  kokorotts-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16